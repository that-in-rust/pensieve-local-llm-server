[workspace]
resolver = "2"
members = [
    "p01-cli-interface-launcher",
    "p02-http-server-core",
    "p03-api-model-types",
    "p04-inference-engine-core",
    "p05-model-storage-core",
    "p06-metal-gpu-accel",
    "p07-foundation-types",
    "p08-claude-api-core",
    "p09-api-proxy-compat",
]

[workspace.package]
version = "0.1.0"
edition = "2021"
rust-version = "1.75"
authors = ["Pensieve Contributors"]
license = "MIT OR Apache-2.0"
description = "Local LLM inference server with Anthropic API compatibility"

[workspace.dependencies]
# Core dependencies
tokio = { version = "1.40", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "1.0"
anyhow = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }
uuid = { version = "1.0", features = ["v4", "serde"] }
async-trait = "0.1"
clap = { version = "4.5", features = ["derive"] }

# HTTP and networking
warp = "0.3"
hyper = { version = "0.14", features = ["full"] }
reqwest = { version = "0.11", features = ["json", "stream"] }

# ML/Model dependencies
candle-core = "0.8"
candle-nn = "0.8"
candle-transformers = "0.8"
safetensors = "0.4"
tokenizers = "0.19"

# Async utilities
futures = "0.3"
async-stream = "0.3"

# Testing
proptest = "1.9"
criterion = "0.5"
tokio-test = "0.4"

# System monitoring
sysinfo = "0.30"

# Time/Date
chrono = "0.4"