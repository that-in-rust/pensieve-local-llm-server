Convert a large text file to smaller chunks of equal size

"Hey, ever split a pizza into equal slices? That's exactly what we're doing with text files!"

ğŸ¯ Goal: Split a large text file into smaller chunks of equal size (N MB each)

ğŸ“‹ PRD (Product Requirements Document):
1. Input: Accept any text file regardless of size
2. Output: Generate files of equal size of N MB each as shared by user in cargo run N (Â±1KB tolerance)
3. Performance: Process 1GB file in under 30 seconds
4. Memory: Max usage = 2x buffer size (default 1MB)
5. Recovery: Auto-resume on failure, cleanup incomplete files
6. CLI Interface: Simple flags (-i input -s size -o output_dir)
7. Progress: Show real-time progress bar and ETA
8. Validation: Verify output files match input checksum

System Architecture:
```
Input File (big.txt)           Output Files
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              â”‚         â”Œâ”€â”€â”€â–¶â”‚ chunk_1.txtâ”‚
â”‚   Large      â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   Text       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   File       â”‚         â”œâ”€â”€â”€â–¶â”‚ chunk_2.txtâ”‚
â”‚              â”‚         â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â””â”€â”€â”€â–¶â”‚ chunk_n.txtâ”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Code Structure:
```rust
src/
â”œâ”€â”€ main.rs         // CLI handling & entry point
â”œâ”€â”€ chunker.rs      // File splitting logic
â”œâ”€â”€ progress.rs     // Progress bar & ETA tracking
â””â”€â”€ utils.rs        // Helper functions & checksums

// Flow of execution:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Parse CLI   â”‚â”€â”€â”€â”€â–¶â”‚ Read Source  â”‚â”€â”€â”€â”€â–¶â”‚ Calculate  â”‚
â”‚ -i -s -o    â”‚     â”‚ File Stats   â”‚     â”‚ Chunks     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚ Write &     â”‚â—€â”€â”€â”€â”€â”‚ Split Into   â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ Track Progress    â”‚ Chunks       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Example Usage:
```rust
fn main() {
    let args = Args::parse();  // Uses clap for CLI parsing
    println!("ğŸ”¨ File Splitter Starting...");
    
    let pb = ProgressBar::new(total_bytes);
    let chunks = split_file(&args.input, args.size_mb, &args.output_dir, &pb)?;
    
    println!("âœ… Created {} chunks", chunks.len());
    println!("ğŸ“‚ Output directory: {}", args.output_dir);
}
```

Memory Management:
```
Buffer Strategy:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Read Buffer    â”‚ 1MB
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Write Buffer   â”‚ 1MB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    â”Œâ”€â”€â”€ Controlled memory usage
                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”´â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input    â”‚â”€â”€â”€â–¶â”‚Bufferâ”‚â”€â”€â”€â–¶â”‚ Output   â”‚
â”‚ Stream   â”‚    â”‚      â”‚    â”‚ Stream   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Error Handling:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Error  â”‚â”€â”€â”
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ File Error  â”‚â”€â”€â”´â”€â”€â”€â–¶â”‚ Error Handler â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”˜
â”‚ IO Error    â”‚â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Performance Considerations:
```
ğŸš€ Speed Optimizations:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Buffered Reading   â”‚ Reduces system calls
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Parallel Writing   â”‚ Multiple chunks at once
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Memory Mapping     â”‚ For very large files
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ğŸ’¡ Key Features:
- Handles files larger than available RAM
- Progress reporting
- Checksum verification
- Resume capability
- Clean error handling

ğŸ” Design Choices:
- Uses BufReader/BufWriter for efficiency
- Streams data instead of loading entire file
- Maintains original file permissions
